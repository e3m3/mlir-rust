// RUN: %O/run tensor_concat_1 2>&1 | @mlir-opt | @filecheck %M/tensor_concat_1.mlir --check-prefix=CHECK_CAN

extern crate mlir;

use crate::common::*;

use mlir::dialects::IOperation;
use mlir::dialects::common::Dimension;
use mlir::dialects::func::Return;
use mlir::dialects::tensor::Concat;
use mlir::ir::Block;
use mlir::ir::ShapeImpl;
use mlir::types::IType;
use mlir::types::float::Float as FloatType;
use mlir::types::float::Layout as FloatLayout;
use mlir::types::ranked_tensor::RankedTensor;

pub fn test() -> TestResult {
    let mut module = get_module(&get_registry());
    let context = module.get_context();
    let loc = context.get_unknown_location();
    let t = FloatType::new(&context, FloatLayout::F32).as_type();
    let s_a = ShapeImpl::from(vec![3, 6]);
    let s_b = ShapeImpl::from(vec![1, 6]);
    let s_out = ShapeImpl::from(vec![7, 6]);
    let t_tnsr_a = RankedTensor::new(&s_a, &t);
    let t_tnsr_b = RankedTensor::new(&s_b, &t);
    let t_tnsr_out = RankedTensor::new(&s_out, &t);
    let f = get_empty_test_fn(
        &context,
        &[t_tnsr_a.as_type(), t_tnsr_a.as_type(), t_tnsr_b.as_type()],
        &[t_tnsr_out.as_type()],
    );
    let f_region = f.as_operation().iter().next().unwrap_or_default();
    let mut f_block = f_region.iter().next().unwrap_or_default();
    let dim = Dimension::new(&context, 0);
    let mut op_concat = Concat::new(
        &t_tnsr_out,
        &[f_block.get_arg(0), f_block.get_arg(1), f_block.get_arg(2)],
        &dim,
        &loc,
    )
    .as_operation();
    let mut op_ret = Return::new(&f, &[op_concat.get_result(0)], &loc).as_operation();
    f_block.append_operation(&mut op_concat);
    f_block.append_operation(&mut op_ret);
    let mut block = Block::new_empty();
    block.append_operation(&mut f.as_operation());
    module.take_body(&mut block);
    module.as_operation().dump();
    Ok(())
}
