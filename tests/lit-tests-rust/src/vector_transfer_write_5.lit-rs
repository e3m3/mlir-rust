// RUN: %O/run vector_transfer_write_5 2>&1 | @mlir-opt | @filecheck %M/vector_transfer_write_5.mlir --check-prefix=CHECK_CAN

// COM: This test fails to verify because `mlir-opt` says that this operation cannot have
// COM: broadcast dimensions.
// COM: This conflicts with the 0-d tensor example in [1].
// COM: [1]: `https://mlir.llvm.org/docs/Dialects/Vector/#vectortransfer_write-vectortransferwriteop`
// XFAIL: *

extern crate mlir;

use crate::common::*;

use mlir::attributes::specialized::NamedAffineMap;
use mlir::dialects::IOperation;
use mlir::dialects::affine::IExpr;
use mlir::dialects::affine::Constant as AffineConstant;
use mlir::dialects::affine::Map as AffineMap;
use mlir::dialects::func::Return;
use mlir::dialects::vector::InBounds;
use mlir::dialects::vector::PermutationMap;
use mlir::dialects::vector::TransferWrite;
use mlir::ir::Block;
use mlir::ir::Shape;
use mlir::ir::ShapeImpl;
use mlir::types::IType;
use mlir::types::float::Float as FloatType;
use mlir::types::float::Layout as FloatLayout;
use mlir::types::ranked_tensor::RankedTensor;
use mlir::types::vector::Vector;

pub fn test() -> TestResult {
    let mut module = get_module(&get_registry());
    let context = module.get_context();
    let loc = context.get_unknown_location();
    let t = FloatType::new(&context, FloatLayout::F32).as_type();
    let s_out = ShapeImpl::from(vec![]);
    let s_in = ShapeImpl::from(vec![1]);
    let t_vec_in = Vector::new(&s_in, &t).as_type();
    let t_tnsr_out = RankedTensor::new(&s_out, &t);
    let f = get_empty_test_fn(&context, &[t_tnsr_out.as_type(), t_vec_in.clone()], &[
        t_tnsr_out.as_type(),
    ]);
    let f_region = f.as_operation().iter().next().unwrap_or_default();
    let mut f_block = f_region.iter().next().unwrap_or_default();
    let bounds_attr = InBounds::new(&context, &[true]);
    let affine_c0 = AffineConstant::new(&context, 0).as_expr();
    let map = AffineMap::new_results(&context, s_out.rank(), 0, &[affine_c0]);
    let perm_attr = PermutationMap::new(map);
    let mut op_write = TransferWrite::new_tensor(
        &t_tnsr_out,
        &bounds_attr,
        &perm_attr,
        &f_block.get_arg(1),
        &f_block.get_arg(0),
        &[],
        None,
        &loc,
    )
    .as_operation();
    let mut op_ret = Return::new(&f, &[op_write.get_result(0)], &loc).as_operation();
    f_block.append_operation(&mut op_write);
    f_block.append_operation(&mut op_ret);
    let mut block = Block::new_empty();
    block.append_operation(&mut f.as_operation());
    module.take_body(&mut block);
    module.as_operation().dump();
    Ok(())
}
